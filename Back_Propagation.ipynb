{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Finyasy/BackPropagation/blob/main/Back_Propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ChBbac4y8PPq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "id": "x6GhEWW18aCS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6477b688-559f-4ea5-c2c0-8be21bb35a35"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-08 14:10:00--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt.1’\n",
            "\n",
            "\rnames.txt.1           0%[                    ]       0  --.-KB/s               \rnames.txt.1         100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2026-01-08 14:10:00 (11.0 MB/s) - ‘names.txt.1’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "klmu3ZG08PPr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2544b3a6-81e2-46ac-d91d-4c9943c0361d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32033\n",
            "15\n",
            "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
          ]
        }
      ],
      "source": [
        "# read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "print(len(words))\n",
        "print(max(len(w) for w in words))\n",
        "print(words[:8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BCQomLE_8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79659a1c-272b-4d33-a3f3-0a82a25a2177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "V_zt2QHr8PPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3b6a2c-e906-40ff-b9fd-f7a671ee28c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ],
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], []\n",
        "\n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "eg20-vsg8PPt"
      },
      "outputs": [],
      "source": [
        "# ok biolerplate done, now we get to the action:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MJPU8HT08PPu"
      },
      "outputs": [],
      "source": [
        "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
        "def cmp(s, dt, t):\n",
        "  ex = torch.all(dt == t.grad).item()\n",
        "  app = torch.allclose(dt, t.grad)\n",
        "  maxdiff = (dt - t.grad).abs().max().item()\n",
        "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ZlFLjQyT8PPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49f4e5c-f022-42c1-edf6-e11ea80a98fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4137\n"
          ]
        }
      ],
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "# Note: I am initializating many of these parameters in non-standard ways\n",
        "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
        "# implementation of the backward pass.\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QY-y96Y48PPv"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "n = batch_size # a shorter variable also, for convenience\n",
        "# construct a minibatch\n",
        "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8ofj1s6d8PPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e01a16-82cf-43ea-c6da-21f5a3cf0050"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.3313, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
        "\n",
        "emb = C[Xb] # embed the characters into vectors\n",
        "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "# Linear layer 1\n",
        "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "# BatchNorm layer\n",
        "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "bndiff = hprebn - bnmeani\n",
        "bndiff2 = bndiff**2\n",
        "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "bnraw = bndiff * bnvar_inv\n",
        "hpreact = bngain * bnraw + bnbias\n",
        "# Non-linearity\n",
        "h = torch.tanh(hpreact) # hidden layer\n",
        "# Linear layer 2\n",
        "logits = h @ W2 + b2 # output layer\n",
        "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
        "logit_maxes = logits.max(1, keepdim=True).values\n",
        "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "counts = norm_logits.exp()\n",
        "counts_sum = counts.sum(1, keepdims=True)\n",
        "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "probs = counts * counts_sum_inv\n",
        "logprobs = probs.log()\n",
        "loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# PyTorch backward pass\n",
        "for p in parameters:\n",
        "  p.grad = None\n",
        "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
        "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
        "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
        "         embcat, emb]:\n",
        "  t.retain_grad()\n",
        "loss.backward()\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Yb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIXLreCZ45yc",
        "outputId": "5404c30e-5baf-46f9-ee17-e52e33cd43ed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 8, 14, 15, 22,  0, 19,  9, 14,  5,  1, 20,  3,  8, 14, 12,  0, 11,  0,\n",
              "        26,  9, 25,  0,  1,  1,  7, 18,  9,  3,  5,  9,  0, 18])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(range(n))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKHrPd425Dnz",
        "outputId": "ead61a49-81bb-47e4-9062-9ad45c35fe75"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "range(0, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs[0, 8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "achEfM3c5J4d",
        "outputId": "3ca64c2d-a5c8-4820-e78d-d773db5cca8f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-3.9655, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs[1, 14]"
      ],
      "metadata": {
        "id": "3YlbUKPM5i-b",
        "outputId": "3384d8c5-d4f9-43af-a731-231463e6370e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-2.9777, grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logprobs[range(n), Yb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo_gshhi4xWE",
        "outputId": "0f8243d6-ca42-4d39-c3f2-74cfb9af0529"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.9655, -2.9777, -3.5805, -3.2588, -4.0602, -3.4608, -3.1881, -3.9744,\n",
            "        -3.1762, -4.3722, -3.0687, -1.5295, -2.7920, -2.9483, -2.9455, -3.2162,\n",
            "        -3.8758, -2.9896, -3.5418, -3.3734, -2.8481, -2.9557, -4.3932, -4.0338,\n",
            "        -3.4874, -2.9303, -3.0583, -3.8741, -2.7317, -3.4770, -3.2686, -3.2495],\n",
            "       grad_fn=<IndexBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs[range(n), Yb].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2b7Puc5Azlc",
        "outputId": "19365ea8-0b40-45b8-96e3-076f74e0d065"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqFMyoUd217q",
        "outputId": "ce95cb55-b346-44fa-a74b-cb48e9a17fa9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logprobs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-IicV1R29vq",
        "outputId": "de41ac8b-76f8-4742-8193-a030b8252f2a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.6294, -2.5076, -4.0290, -2.9826, -3.9459, -2.4734, -3.7856, -3.3645,\n",
              "         -3.9655, -3.4865, -3.2766, -3.3524, -3.2707, -3.5939, -3.2692, -4.2577,\n",
              "         -4.7919, -3.8966, -4.2219, -2.8544, -2.9590, -3.8434, -3.6834, -2.6719,\n",
              "         -2.8322, -3.6103, -3.7842],\n",
              "        [-2.9914, -2.8926, -2.4546, -2.8405, -3.3771, -3.3742, -3.9799, -3.0854,\n",
              "         -3.9093, -3.7011, -2.9494, -3.2202, -2.9865, -3.5793, -2.9777, -3.1915,\n",
              "         -3.6756, -4.1067, -3.9019, -3.1648, -3.9046, -3.7323, -4.2481, -2.8493,\n",
              "         -3.6814, -3.2488, -3.6758],\n",
              "        [-3.8911, -3.7930, -4.3204, -4.3043, -3.8357, -3.2124, -2.8371, -2.8219,\n",
              "         -2.7588, -3.5194, -3.8417, -3.3736, -3.0337, -3.0700, -3.7163, -3.5805,\n",
              "         -4.4071, -3.2888, -3.7144, -2.1375, -2.7393, -3.3716, -3.1740, -3.2949,\n",
              "         -3.3243, -3.8743, -3.5600],\n",
              "        [-3.4805, -3.7881, -3.1709, -2.9042, -2.7817, -3.5545, -3.1572, -3.2692,\n",
              "         -3.0357, -3.9820, -3.2706, -3.7257, -3.3160, -3.2165, -2.7297, -2.6648,\n",
              "         -3.7480, -3.7362, -4.1810, -2.8954, -3.9888, -3.7616, -3.2588, -3.9244,\n",
              "         -3.6116, -3.0441, -3.0766],\n",
              "        [-4.0602, -4.1805, -3.7538, -3.7348, -4.0730, -3.2413, -3.3924, -4.1090,\n",
              "         -2.8896, -3.2671, -3.3924, -4.1838, -3.2477, -3.7897, -3.0140, -1.7131,\n",
              "         -4.0388, -2.9805, -3.0945, -2.7824, -3.1997, -4.2131, -3.8226, -4.2853,\n",
              "         -3.1298, -3.7365, -3.0756],\n",
              "        [-3.3604, -3.4428, -2.9278, -2.7109, -2.7182, -3.6510, -3.5190, -2.9070,\n",
              "         -3.6449, -4.1664, -3.1124, -4.0604, -3.5504, -3.1672, -2.6507, -2.9524,\n",
              "         -4.0953, -3.9339, -4.6918, -3.4608, -3.4526, -3.5237, -3.1551, -4.0708,\n",
              "         -4.0178, -2.5274, -3.1112],\n",
              "        [-2.8862, -4.5823, -2.7326, -4.1329, -3.5795, -3.9009, -2.7441, -2.9435,\n",
              "         -2.9886, -3.1881, -3.9931, -3.4629, -3.5860, -4.0033, -4.0887, -2.5803,\n",
              "         -2.5335, -3.1035, -4.6173, -3.3217, -3.6143, -3.0098, -3.0682, -3.9588,\n",
              "         -3.2691, -3.6409, -3.4550],\n",
              "        [-3.1729, -3.5507, -3.7694, -2.1550, -3.5653, -2.9854, -3.5705, -2.5069,\n",
              "         -3.2637, -4.7714, -3.5866, -4.2718, -3.8801, -2.8928, -3.9744, -4.1076,\n",
              "         -4.3265, -4.3180, -4.2806, -2.3468, -3.3365, -2.9921, -3.5829, -3.3774,\n",
              "         -3.7033, -2.8709, -3.2890],\n",
              "        [-3.0276, -3.5124, -4.1230, -3.2162, -4.5745, -3.1762, -3.0046, -2.4448,\n",
              "         -3.5623, -3.9635, -3.5406, -3.5066, -3.2441, -3.7929, -4.4051, -3.9310,\n",
              "         -4.0034, -3.2473, -3.8580, -2.3054, -3.3097, -2.4840, -3.1146, -3.1690,\n",
              "         -3.1283, -4.1415, -3.4020],\n",
              "        [-3.5443, -4.3722, -3.5236, -3.9827, -3.4810, -3.2581, -3.3448, -3.6065,\n",
              "         -2.4014, -2.8144, -4.2809, -3.3689, -3.1712, -3.2237, -3.6639, -3.3720,\n",
              "         -2.8204, -3.1023, -3.2529, -3.6535, -2.6607, -3.6720, -2.7168, -4.0528,\n",
              "         -3.4230, -3.2706, -3.9251],\n",
              "        [-4.1996, -4.9999, -3.3675, -3.1529, -3.4182, -3.3291, -4.0124, -5.1573,\n",
              "         -3.2489, -3.0883, -3.6447, -4.1019, -2.8271, -3.6161, -3.1764, -1.8602,\n",
              "         -2.9792, -2.8674, -2.6322, -3.3261, -3.0687, -4.5697, -4.4196, -3.8352,\n",
              "         -3.2323, -3.5766, -3.7030],\n",
              "        [-3.7943, -3.5424, -3.8545, -1.5295, -4.4746, -2.8723, -2.7943, -3.1215,\n",
              "         -3.2007, -3.6326, -4.2281, -4.1131, -3.8553, -3.6333, -4.9886, -4.9389,\n",
              "         -3.9280, -3.3831, -4.2571, -2.8385, -2.9406, -3.2745, -3.9799, -3.3851,\n",
              "         -3.0751, -3.0793, -4.1283],\n",
              "        [-3.9885, -4.3932, -3.0248, -4.1956, -3.6746, -4.1941, -2.5184, -3.3171,\n",
              "         -2.7920, -2.9930, -4.1031, -3.3120, -3.1891, -3.5041, -4.1632, -3.0413,\n",
              "         -2.6626, -3.0912, -3.3259, -3.7603, -3.0501, -3.2383, -2.2980, -4.6520,\n",
              "         -3.8490, -3.5794, -3.5418],\n",
              "        [-3.7804, -3.7000, -3.0082, -3.8711, -4.1179, -2.5837, -3.5543, -4.2062,\n",
              "         -3.4562, -3.0468, -3.5206, -3.4358, -2.6416, -3.4029, -2.9483, -2.9481,\n",
              "         -3.5695, -3.3458, -2.6388, -4.1852, -2.7503, -4.1836, -4.0038, -3.4394,\n",
              "         -3.2666, -3.2112, -3.2506],\n",
              "        [-3.0477, -3.6144, -3.6326, -2.8502, -4.1640, -3.3614, -3.4421, -2.8567,\n",
              "         -2.9567, -3.0335, -3.5196, -3.1036, -2.9455, -3.3286, -3.5589, -3.6581,\n",
              "         -3.9109, -2.8958, -3.6597, -2.9359, -2.9173, -3.0209, -3.6765, -3.3943,\n",
              "         -3.7464, -3.8247, -3.7686],\n",
              "        [-3.2162, -2.8779, -3.4938, -3.8943, -3.9992, -2.4275, -3.4843, -3.8280,\n",
              "         -3.5363, -3.0026, -3.3277, -3.1502, -2.6755, -4.0996, -3.5009, -3.9825,\n",
              "         -3.2590, -3.8867, -2.9543, -3.9151, -3.2229, -3.6622, -3.4312, -2.7711,\n",
              "         -2.8406, -3.4723, -3.8524],\n",
              "        [-3.5529, -3.8088, -2.6152, -3.0986, -2.7290, -2.9571, -4.1789, -3.6384,\n",
              "         -3.9024, -3.9665, -2.9609, -3.8758, -3.2109, -2.9580, -2.5555, -2.6752,\n",
              "         -4.2065, -4.0946, -3.8854, -3.0915, -3.5942, -4.0524, -4.6483, -3.1471,\n",
              "         -3.6886, -3.1022, -2.8698],\n",
              "        [-2.9896, -2.6038, -3.0756, -2.9340, -3.2413, -3.4322, -3.8605, -2.5930,\n",
              "         -3.6602, -4.0945, -2.5955, -4.3190, -3.6962, -4.0167, -3.0869, -3.5203,\n",
              "         -4.3064, -3.4904, -4.1460, -2.8566, -3.8807, -3.1039, -3.5947, -3.9838,\n",
              "         -3.7458, -3.1294, -2.7415],\n",
              "        [-3.9885, -4.3932, -3.0248, -4.1956, -3.6746, -4.1941, -2.5184, -3.3171,\n",
              "         -2.7920, -2.9930, -4.1031, -3.3120, -3.1891, -3.5041, -4.1632, -3.0413,\n",
              "         -2.6626, -3.0912, -3.3259, -3.7603, -3.0501, -3.2383, -2.2980, -4.6520,\n",
              "         -3.8490, -3.5794, -3.5418],\n",
              "        [-3.7614, -3.9241, -3.4363, -4.0976, -3.3324, -3.3926, -2.6660, -2.9965,\n",
              "         -3.3256, -3.3734, -3.4893, -3.1382, -2.7433, -2.9458, -4.2029, -3.6795,\n",
              "         -3.6477, -3.8739, -3.6480, -2.3526, -2.9876, -3.4342, -3.1528, -3.1271,\n",
              "         -3.4714, -3.7164, -3.6677],\n",
              "        [-2.9351, -4.3965, -4.1301, -3.2426, -3.4501, -3.2838, -3.6617, -3.3009,\n",
              "         -2.8930, -3.8015, -2.6916, -3.3634, -2.7844, -3.8769, -3.0413, -2.5650,\n",
              "         -4.1601, -3.8864, -3.3902, -2.8666, -3.9313, -3.5265, -3.7285, -3.7082,\n",
              "         -3.3080, -2.8481, -3.1822],\n",
              "        [-2.9557, -2.6748, -3.1016, -2.9891, -3.6552, -2.7543, -3.5380, -3.1751,\n",
              "         -3.7989, -4.0881, -2.9306, -3.6607, -3.6643, -3.5194, -3.0568, -3.0494,\n",
              "         -4.0003, -3.3760, -4.0614, -2.3533, -4.3039, -3.4360, -4.2413, -3.5210,\n",
              "         -3.3213, -3.5098, -3.3527],\n",
              "        [-3.9885, -4.3932, -3.0248, -4.1956, -3.6746, -4.1941, -2.5184, -3.3171,\n",
              "         -2.7920, -2.9930, -4.1031, -3.3120, -3.1891, -3.5041, -4.1632, -3.0413,\n",
              "         -2.6626, -3.0912, -3.3259, -3.7603, -3.0501, -3.2383, -2.2980, -4.6520,\n",
              "         -3.8490, -3.5794, -3.5418],\n",
              "        [-3.0436, -4.0338, -3.6010, -4.3302, -2.9161, -3.6569, -2.7304, -3.5417,\n",
              "         -3.7083, -3.2475, -3.3958, -3.3557, -3.3410, -3.4075, -3.1665, -2.9222,\n",
              "         -2.6023, -3.8316, -3.4022, -4.1152, -3.9794, -3.7953, -2.1734, -4.0747,\n",
              "         -2.9004, -3.4007, -4.0141],\n",
              "        [-3.4524, -2.5651, -3.8705, -2.9909, -3.6405, -2.6751, -3.8222, -3.4874,\n",
              "         -3.6599, -3.5627, -2.3050, -4.1790, -3.4839, -4.3876, -3.1797, -3.9221,\n",
              "         -4.1841, -4.2276, -4.4221, -3.4771, -4.3524, -3.7563, -4.4854, -1.9099,\n",
              "         -2.9419, -3.6151, -2.9752],\n",
              "        [-2.7893, -3.6264, -4.1850, -3.9044, -3.5065, -2.4964, -3.2058, -3.4974,\n",
              "         -3.6275, -3.3776, -3.4507, -3.0629, -2.7996, -3.4221, -3.8394, -4.2312,\n",
              "         -3.4419, -3.8540, -2.9303, -4.2362, -3.5849, -3.8362, -2.6225, -2.9586,\n",
              "         -2.6411, -3.0578, -4.4639],\n",
              "        [-3.1753, -3.7550, -3.8055, -4.5390, -3.1241, -3.8763, -2.4396, -3.2652,\n",
              "         -3.5131, -3.0583, -4.0336, -3.1667, -2.7601, -3.4648, -3.5476, -3.9037,\n",
              "         -2.8899, -3.6444, -3.5762, -3.3162, -3.7820, -3.3372, -2.0159, -4.0786,\n",
              "         -3.2811, -3.5253, -4.5870],\n",
              "        [-3.6071, -3.6585, -3.0893, -3.8741, -3.3989, -3.7504, -3.2662, -3.5436,\n",
              "         -3.2102, -2.9300, -3.9243, -3.6156, -3.2347, -3.3755, -3.0781, -2.6623,\n",
              "         -3.0682, -3.0767, -3.1211, -4.0863, -2.3244, -4.1969, -3.0260, -4.5591,\n",
              "         -3.9930, -3.3221, -3.0557],\n",
              "        [-2.7271, -3.2473, -4.2391, -3.8172, -3.4025, -2.7317, -3.2078, -3.3122,\n",
              "         -4.5987, -3.7344, -3.1006, -3.6333, -3.6063, -3.8497, -3.5960, -3.3710,\n",
              "         -2.6161, -3.7460, -2.8566, -3.6046, -3.3779, -3.4124, -3.0410, -2.9077,\n",
              "         -2.4730, -4.3568, -3.8918],\n",
              "        [-3.8036, -4.2682, -3.4503, -3.4016, -2.9853, -3.7633, -2.7293, -3.5054,\n",
              "         -2.6157, -3.4770, -3.5086, -3.4062, -3.4445, -3.3382, -3.3289, -2.6314,\n",
              "         -3.5392, -3.6560, -3.4702, -3.4623, -3.1382, -3.6368, -2.8330, -4.3621,\n",
              "         -3.4504, -2.8687, -3.2158],\n",
              "        [-3.2686, -3.0149, -3.7282, -2.6783, -3.1157, -2.9482, -3.4213, -3.4998,\n",
              "         -3.7336, -3.9516, -3.2663, -3.8871, -3.9980, -3.6332, -4.4269, -3.3608,\n",
              "         -3.4409, -3.6052, -3.1986, -2.8333, -2.9015, -3.6534, -3.8155, -2.6212,\n",
              "         -2.4701, -3.8496, -3.6123],\n",
              "        [-3.1380, -3.8615, -2.6474, -3.9690, -2.6143, -3.5859, -4.0623, -3.7755,\n",
              "         -4.1699, -2.8950, -3.5934, -3.5721, -3.3214, -2.5843, -3.1496, -3.0385,\n",
              "         -3.0059, -3.1841, -3.2495, -4.2822, -2.8350, -4.5566, -2.7813, -3.8951,\n",
              "         -3.8416, -3.2330, -3.9022]], grad_fn=<LogBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts.shape, counts_sum_inv.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Es7V8bvKX4I",
        "outputId": "a3f940a6-95aa-4b39-ac40-6faff347a39e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]), torch.Size([32, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "mO-8aqxK8PPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba857edb-0fab-42e1-e505-3e1761371dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
            "hpreact         | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bngain          | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "bnbias          | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
            "bnraw           | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bnvar_inv       | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n",
            "bnvar           | exact: False | approximate: True  | maxdiff: 6.984919309616089e-10\n",
            "bndiff2         | exact: False | approximate: True  | maxdiff: 2.1827872842550278e-11\n",
            "bndiff          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "bnmeani         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
            "hprebn          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
            "embcat          | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "W1              | exact: False | approximate: True  | maxdiff: 4.6566128730773926e-09\n",
            "b1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n",
            "emb             | exact: False | approximate: True  | maxdiff: 1.1641532182693481e-09\n",
            "C               | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n"
          ]
        }
      ],
      "source": [
        "dlogprobs = torch.zeros_like(logprobs)\n",
        "dlogprobs[range(n),Yb] = -1.0/n\n",
        "dprobs = (1.0 / probs) * dlogprobs\n",
        "dcounts_sum_inv = (counts * dprobs).sum(1,keepdim = True)\n",
        "dcounts =  counts_sum_inv * dprobs\n",
        "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
        "dcounts += torch.ones_like(counts) * dcounts_sum\n",
        "dnorm_logits = counts * dcounts\n",
        "dlogits = dnorm_logits.clone()\n",
        "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
        "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
        "dh = dlogits @ W2.T\n",
        "dW2 = h.T @ dlogits\n",
        "db2 = dlogits.sum(0)\n",
        "dhpreact = (1.0 - h**2) * dh\n",
        "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
        "dbnbias = dhpreact.sum(0, keepdim=True)\n",
        "dbnraw = bngain * dhpreact\n",
        "\n",
        "dbndiff_part1 = bnvar_inv * dbnraw\n",
        "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "dbnvar = (-0.5 * (bnvar + 1e-5)**(-1.5)) * dbnvar_inv\n",
        "dbndiff2 = (1.0/(n-1)) * torch.ones_like(bndiff2) * dbnvar\n",
        "dbndiff_part2 = (2 * bndiff) * dbndiff2\n",
        "dbndiff = dbndiff_part1 + dbndiff_part2\n",
        "dhprebn_part1 = dbndiff.clone()\n",
        "dbnmeani = -dbndiff.sum(0, keepdim=True)\n",
        "dhprebn_part2 = (1.0/n) * torch.ones_like(hprebn) * dbnmeani\n",
        "dhprebn = dhprebn_part1 + dhprebn_part2\n",
        "\n",
        "dembcat = dhprebn @ W1.T\n",
        "dW1 = embcat.T @ dhprebn\n",
        "db1 = dhprebn.sum(0)\n",
        "demb = dembcat.view(emb.shape)\n",
        "dC = torch.zeros_like(C)\n",
        "dC.index_add_(0, Xb.view(-1), demb.view(-1, n_embd))\n",
        "\n",
        "cmp('logprobs', dlogprobs, logprobs)\n",
        "cmp('probs', dprobs, probs)\n",
        "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
        "cmp('counts_sum', dcounts_sum, counts_sum)\n",
        "cmp('counts', dcounts, counts)\n",
        "cmp('norm_logits', dnorm_logits, norm_logits)\n",
        "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
        "cmp('logits', dlogits, logits)\n",
        "cmp('h', dh, h)\n",
        "cmp('W2', dW2, W2)\n",
        "cmp('b2', db2, b2)\n",
        "cmp('hpreact', dhpreact, hpreact)\n",
        "cmp('bngain', dbngain, bngain)\n",
        "cmp('bnbias', dbnbias, bnbias)\n",
        "cmp('bnraw', dbnraw, bnraw)\n",
        "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
        "cmp('bnvar', dbnvar, bnvar)\n",
        "cmp('bndiff2', dbndiff2, bndiff2)\n",
        "cmp('bndiff', dbndiff, bndiff)\n",
        "cmp('bnmeani', dbnmeani, bnmeani)\n",
        "cmp('hprebn', dhprebn, hprebn)\n",
        "cmp('embcat', dembcat, embcat)\n",
        "cmp('W1', dW1, W1)\n",
        "cmp('b1', db1, b1)\n",
        "cmp('emb', demb, emb)\n",
        "cmp('C', dC, C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ebLtYji_8PPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733db565-4f5d-4b14-ffc9-ce3b3b5db528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3313357830047607 diff: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Exercise 2: backprop through cross_entropy but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the loss,\n",
        "# take the derivative, simplify the expression, and just write it out\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# logit_maxes = logits.max(1, keepdim=True).values\n",
        "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
        "# counts = norm_logits.exp()\n",
        "# counts_sum = counts.sum(1, keepdims=True)\n",
        "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
        "# probs = counts * counts_sum_inv\n",
        "# logprobs = probs.log()\n",
        "# loss = -logprobs[range(n), Yb].mean()\n",
        "\n",
        "# now:\n",
        "loss_fast = F.cross_entropy(logits, Yb)\n",
        "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-gCXbB4C8PPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a060413a-3f36-4be0-df39-024d5233c19b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits          | exact: False | approximate: True  | maxdiff: 5.820766091346741e-09\n"
          ]
        }
      ],
      "source": [
        "# backward pass\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "dlogits = F.softmax(logits,1)\n",
        "dlogits[range(n),Yb] -=1\n",
        "dlogits /= n\n",
        "# -----------------\n",
        "\n",
        "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(figsize=(8,8))\n",
        "plt.imshow(dlogits.detach(),cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "rmy9ydzoQb4o",
        "outputId": "6cd34dde-947c-44ff-965d-70522fc92d14"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e45f51819a0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "hd-MkhB68PPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b8773d1-db06-45d1-c6cf-c3ce8197077f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# Exercise 3: backprop through batchnorm but all in one go\n",
        "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
        "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
        "# BatchNorm paper: https://arxiv.org/abs/1502.03167\n",
        "\n",
        "# forward pass\n",
        "\n",
        "# before:\n",
        "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
        "# bndiff = hprebn - bnmeani\n",
        "# bndiff2 = bndiff**2\n",
        "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
        "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "# bnraw = bndiff * bnvar_inv\n",
        "# hpreact = bngain * bnraw + bnbias\n",
        "\n",
        "# now:\n",
        "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
        "print('max diff:', (hpreact_fast - hpreact).abs().max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "POdeZSKT8PPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9c3419-9235-4c11-8def-e8d29bfb4666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
          ]
        }
      ],
      "source": [
        "# backward pass\n",
        "\n",
        "# before we had:\n",
        "# dbnraw = bngain * dhpreact\n",
        "# dbndiff = bnvar_inv * dbnraw\n",
        "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
        "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
        "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
        "# dbndiff += (2*bndiff) * dbndiff2\n",
        "# dhprebn = dbndiff.clone()\n",
        "# dbnmeani = (-dbndiff).sum(0)\n",
        "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
        "\n",
        "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
        "# (you'll also need to use some of the variables from the forward pass up above)\n",
        "\n",
        "# -----------------\n",
        "# YOUR CODE HERE :)\n",
        "# dhprebn = None # TODO. my solution is 1 (long) line\n",
        "dhprebn = bngain*bnvar_inv/n * (n * dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
        "# -----------------\n",
        "\n",
        "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "wPy8DhqB8PPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da264d32-ed11-4b8d-e38f-2974a9cea27c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12297\n",
            "      0/ 200000: 3.7357\n"
          ]
        }
      ],
      "source": [
        "# Exercise 4: putting it all together!\n",
        "# Train the MLP neural net with your own backward pass\n",
        "\n",
        "# init\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "# Layer 1\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
        "# Layer 2\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
        "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
        "# BatchNorm parameters\n",
        "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
        "bnbias = torch.randn((1, n_hidden))*0.1\n",
        "\n",
        "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True\n",
        "\n",
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "n = batch_size # convenience\n",
        "lossi = []\n",
        "\n",
        "# use this context manager for efficiency once your backward pass is written (TODO)\n",
        "#with torch.no_grad():\n",
        "\n",
        "# kick off optimization\n",
        "for i in range(max_steps):\n",
        "\n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  # Linear layer\n",
        "  hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
        "  # BatchNorm layer\n",
        "  # -------------------------------------------------------------\n",
        "  bnmean = hprebn.mean(0, keepdim=True)\n",
        "  bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
        "  bnvar_inv = (bnvar + 1e-5)**-0.5\n",
        "  bnraw = (hprebn - bnmean) * bnvar_inv\n",
        "  hpreact = bngain * bnraw + bnbias\n",
        "  # -------------------------------------------------------------\n",
        "  # Non-linearity\n",
        "  h = torch.tanh(hpreact) # hidden layer\n",
        "  logits = h @ W2 + b2 # output layer\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "\n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward() # use this for correctness comparisons, delete it later!\n",
        "\n",
        "  # manual backprop! #swole_doge_meme\n",
        "  # -----------------\n",
        "  # YOUR CODE HERE :)\n",
        "  dC, dW1, db1, dW2, db2, dbngain, dbnbias = None, None, None, None, None, None, None\n",
        "  grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
        "  # -----------------\n",
        "\n",
        "  # update\n",
        "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "  for p, grad in zip(parameters, grads):\n",
        "    p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
        "    #p.data += -lr * grad # new way of swole doge TODO: enable\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "  if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "ZEpI0hMW8PPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "a5c66351-ad3d-4f03-8f1b-8ce85b809c7a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1366618857.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# useful for checking your gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2706152459.py\u001b[0m in \u001b[0;36mcmp\u001b[0;34m(s, dt, t)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# utility function we will use later when comparing manual gradients to PyTorch gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mmaxdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n"
          ]
        }
      ],
      "source": [
        "# useful for checking your gradients\n",
        "for p,g in zip(parameters, grads):\n",
        "  cmp(str(tuple(p.shape)), g, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "KImLWNoh8PP0"
      },
      "outputs": [],
      "source": [
        "# calibrate the batch norm at the end of training\n",
        "\n",
        "with torch.no_grad():\n",
        "  # pass the training set through\n",
        "  emb = C[Xtr]\n",
        "  embcat = emb.view(emb.shape[0], -1)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  # measure the mean/std over the entire training set\n",
        "  bnmean = hpreact.mean(0, keepdim=True)\n",
        "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6aFnP_Zc8PP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3346a3e-8717-4362-8c2e-b74aa2d3f019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.682887315750122\n",
            "val 2.6828420162200928\n"
          ]
        }
      ],
      "source": [
        "# evaluate train and val loss\n",
        "\n",
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  hpreact = embcat @ W1 + b1\n",
        "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "esWqmhyj8PP1"
      },
      "outputs": [],
      "source": [
        "# I achieved:\n",
        "# train 2.0718822479248047\n",
        "# val 2.1162495613098145"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "xHeQNv3s8PP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "879839f2-bd32-4782-e34c-1a2cfb61b24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carmahxqto.\n",
            "hllif.\n",
            "jmrixreetl.\n",
            "hklansaeja.\n",
            "hnbn.\n",
            "apliahc.\n",
            "kaqhi.\n",
            "oremari.\n",
            "cemiiv.\n",
            "kklegg.\n",
            "hhlm.\n",
            "eoi.\n",
            "dqsqbn.\n",
            "shlin.\n",
            "ariadbq.\n",
            "wane.\n",
            "ogdiarixi.\n",
            "fkcekphrran.\n",
            "ea.\n",
            "ecoia.\n"
          ]
        }
      ],
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "\n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
        "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "      hpreact = embcat @ W1 + b1\n",
        "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
        "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
        "      logits = h @ W2 + b2 # (N, vocab_size)\n",
        "      # sample\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      if ix == 0:\n",
        "        break\n",
        "\n",
        "    print(''.join(itos[i] for i in out))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xt7XvuqdW5SQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}